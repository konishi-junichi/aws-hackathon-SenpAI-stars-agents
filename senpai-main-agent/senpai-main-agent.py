import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langgraph.graph import StateGraph, MessagesState
from langgraph.prebuilt import ToolNode, tools_condition

from langchain_core.messages import HumanMessage, SystemMessage
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from bedrock_agentcore.memory import MemoryClient
from langchain_aws import ChatBedrock

# Import logger
from core.logger import setup_logger, get_contextual_logger

# Import ToolFactory and all registered tools
from core.tools.tool_factory import ToolFactory
from core.tools.libs.zundamon_joke_tool import ZundamonJokeTool
from core.tools.libs.chat_history_summarize_tool import Chat_history_summarize_tool
from core.tools.tool_interface import Tool
from prompt import get_prompt


# Initialize logger
logger = setup_logger(
    name="senpai.main_agent",
    level=os.getenv("LOG_LEVEL", "INFO"),
    format_type=os.getenv("LOG_FORMAT", "console"),
    log_file=os.getenv("LOG_FILE")
)

logger.info("Starting SenpAI Main Agent application")

# BedrockAgentCoreã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
app = BedrockAgentCoreApp()

# MemoryClientã®åˆæœŸåŒ–
memory_client = MemoryClient(region_name=os.getenv("AWS_REGION", "us-west-2"))
logger.info("MemoryClient initialized", extra={"region": os.getenv("AWS_REGION", "us-west-2")})

# è¨€èªè¨­å®š
locale = os.getenv("LOCALE", "en_EN")

# LangGraphã‚’ä½¿ç”¨ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ‰‹å‹•æ§‹ç¯‰
def create_agent():
    """LangGraphã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆã¨è¨­å®š"""
    logger.info("Creating LangGraph agent")
    
    # LLMã®åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ï¼‰
    llm = ChatBedrock(
        model_id="us.amazon.nova-micro-v1:0",
        model_kwargs={"temperature": 0.1},
        region_name=os.getenv("AWS_REGION", "us-west-2")
    )
    logger.info("LLM initialized", extra={"model_id": "us.amazon.nova-micro-v1:0"})

    # ToolFactoryã‹ã‚‰å…¨ãƒ„ãƒ¼ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ã—ã€as_langchain_toolã§ãƒ©ãƒƒãƒ—
    tool_instances = [tool_cls() for tool_cls in ToolFactory._registry.values()]
    
    # Store tool instances globally for context setting
    global global_tool_instances
    global_tool_instances = tool_instances
    
    tools = [t.as_langchain_tool() for t in tool_instances]
    llm_with_tools = llm.bind_tools(tools)
    
    logger.info("Tools loaded", extra={"tool_count": len(tools), "tools": [t.name for t in tool_instances]})

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    system_message = get_prompt(locale=locale)

    # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒãƒ¼ãƒ‰ã®å®šç¾©
    def chatbot(state: MessagesState):
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã¾ã å­˜åœ¨ã—ãªã„å ´åˆã¯è¿½åŠ 
        messages = state["messages"]
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=system_message)] + messages

        response = llm_with_tools.invoke(messages)
        return {"messages": [response]}

    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    graph_builder = StateGraph(MessagesState)

    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ 
    graph_builder.add_node("chatbot", chatbot)
    graph_builder.add_node("tools", ToolNode(tools))

    # ã‚¨ãƒƒã‚¸ã®è¿½åŠ 
    graph_builder.add_conditional_edges(
        "chatbot",
        tools_condition,
    )
    graph_builder.add_edge("tools", "chatbot")

    # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š
    graph_builder.set_entry_point("chatbot")

    # ã‚°ãƒ©ãƒ•ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
    compiled_graph = graph_builder.compile()
    logger.info("LangGraph agent compiled successfully")
    return compiled_graph

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
agent = create_agent()
logger.info("Agent created and ready for use")

# Global variable to store tool instances for context setting
global_tool_instances = []

def set_tool_context(user_id: str, session_id: str):
    """Set context for all tool instances."""
    context = {
        "memory_id": os.getenv("AWS_MEMORY_ID", "conversation_memory-y0ttEoDG5r"),
        "actor_id": user_id,
        "user_id": user_id,
        # to-do: use memory or other better way to implement
        "session_id": "session_id_" + user_id
    }

    Tool.set_context(context)  # Update class-level context for any static access

    logger.info("Tool context set", extra=context)

@app.entrypoint
def langgraph_bedrock(payload):
    """
    ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™
    """
    user_input = payload.get("prompt")
    session_id = payload.get("session_id", "default_session")
    user_id = payload.get("user_id", "default_user_konishi")
    
    # Create contextual logger for this request
    request_logger = get_contextual_logger(
        "senpai.request",
        user_id=user_id,
        session_id=session_id
    )
    
    request_logger.info("Processing user request", extra={
        "prompt_length": len(user_input) if user_input else 0,
    })
    
    # Set context for all tools
    set_tool_context(user_id, session_id)
    
    # ä¼šè©±å±¥æ­´ã‚’å–å¾—
    messages = []

    # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è¿½åŠ 
    messages.append(HumanMessage(content=user_input))
    
    try:
        # LangGraphãŒæœŸå¾…ã™ã‚‹å½¢å¼ã§å…¥åŠ›ã‚’ä½œæˆ
        request_logger.info("Invoking LangGraph agent")
        response = agent.invoke({"messages": messages})
        
        # æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹ã‚’æŠ½å‡º
        assistant_response = response["messages"][-1].content
        
        request_logger.info("Agent response generated", extra={
            "response_length": len(assistant_response),
            "total_messages": len(response["messages"])
        })
        
    except Exception as e:
        request_logger.error("Agent invocation failed", extra={"error": str(e)}, exc_info=True)
        return "ç”³ã—è¨³ãªã„ã®ã ï¼ã¡ã‚‡ã£ã¨èª¿å­ãŒæ‚ªã„ã¿ãŸã„ãªã®ã ...ğŸ’§ ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ã¿ã¦ã»ã—ã„ã®ã ï¼"
    
    # AWS AgentCore Memoryã«ä¼šè©±å±¥æ­´ã‚’ä¿å­˜
    try:
        messages_to_save = [(user_input, "USER")]
        for msg in response["messages"][1:]:
            content = msg.content if isinstance(msg.content, str) else str(msg.content)
            messages_to_save.append((content, "ASSISTANT"))
        
        memory_client.create_event(
            memory_id=os.getenv("AWS_MEMORY_ID", "conversation_memory-y0ttEoDG5r"),
            actor_id=user_id,
            # to-do: use memory or other better way to implement
            session_id="session_id_" + user_id,
            messages=messages_to_save,
        )
        
        request_logger.info("Conversation saved to memory", extra={
            "saved_messages": len(messages_to_save)
        })
        
    except Exception as e:
        request_logger.error("Memory save error", extra={"error": str(e)}, exc_info=True)
    
    request_logger.info("Request completed successfully")
    return assistant_response

if __name__ == "__main__":
    logger.info("Starting SenpAI Main Agent server")
    try:
        app.run()
    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error("Server error", extra={"error": str(e)}, exc_info=True)
        raise
